  \documentclass[12pt, a4paper]{report}
\usepackage{amsmath, amssymb}
\usepackage{fancyhdr}
%\setlength{\headheight}{15pt}
\usepackage{geometry}
\geometry{margin=1.5in}
\usepackage[Rejne]{fncychap}
\pagestyle{fancy}
\usepackage{color}
\usepackage{blindtext}
\usepackage{import}
\usepackage{graphicx}
\usepackage{mathrsfs}
\usepackage{trfsigns}
\renewcommand{\chaptername}{Lecture}

\usepackage{import}
\usepackage{pdfpages}
\usepackage{transparent}
\usepackage{xcolor}

\newcommand{\incfig}[2][1]{%
    \def\svgwidth{#1\columnwidth}
    \import{figures}{#2.pdf_tex}
}

\pdfsuppresswarningpagegroup=1



\title{Systems Dynamics Modeling and Analysis}
\author{Adam Carrera}
\date{January 19, 2021}
\lhead{Week \thepart}

\begin{document}
  \maketitle
  \part{Week 1}
  \chapter{Introduction}

  \section{Syllabus and Textbook}

  Instructor Information:
  \begin{enumerate}
    \item Professor Email: Justin.Koeln@UTDallas.edu
    \item Office hours by appointment
    \item TA Email Sahand.HadizadehKafash@UTdallas.edu
    \item Office hours Friday 1:00 pm - 3:00 and by appointment
  \end{enumerate}

  \noindent
  Textbook: System Dynamics, William Palm 3rd Edition. Chapters 1-9 (not in that order), balance of math, theory, modeling, and application.

  \section{Homework}

  Approximately one assignment per week, due Tuesday before class. No late credit for homework and the lowest score will be dropped. Points will be assigned based on the rubric. Each lecture will have a quiz associated with it, due before the start of next class. The quiz is meant to test your understanding of the material.

  \section{Exam Schedule}

  \begin{itemize}
    \item Exam 1: Week of Thursday, Feb. 25
    \item Exam 2: Week of Thursday, Apr. 8
    \item Final Exam: Week of Monday, May 10
  \end{itemize}

  Open book, open notes exams with a time limit. A calculator is allowed and a formula sheet is provided. Additionally, a sheet of equations that we are expected to know if provided as well.

  \begin{table}
    \centering
    \caption{Grading Criteria}
    \label{tab:table1}
    \begin{tabular}{c c}
      Homework & 30\% \\
      Participation & 10\% \\
      Midterm & 15\% each \\
      Final & 30\%
    \end{tabular}
  \end{table}

  \section{Quiz 1}

  \begin{enumerate}
    \item What year are you in school?
    \item Have you taken systems and controls?
    \item Do you have access to Matlab/Simulink
    \item What is the most important thing you want to remember from this lecture?
    \item What are your goals for the course? ..etc
  \end{enumerate}

  \section{Systems}

  A system is a combination of elements intended to act togehter to accomplish an objective. A systems point of view focuses on how the connections between elements influence overall behavior. We can accept a less-detailed description of individual elements to understand the entire system. We want to look at the general behavior of the system as it evolves over time.

  \begin{figure}
    \centering
    \incfig{subsystems}
    \caption{Subsystem Interaction}
  \end{figure}

  \newpage
  \section{Inputs and Outputs}

  \begin{enumerate}
    \item Input is a cause $ u. $
    \item Output is an effect $ y. $
    \item System dynamics are goverened by input-output relationships $ y = f(t, u). $
  \end{enumerate}

  What is $ y = f(t, u). $ and how can we approximate it?

  \begin{figure}
    \centering
    \incfig{inputoutput}
    \caption{Input-Output Relationship}
  \end{figure}

  \section{Dynamics}

  Mechaincal Engineers study how things behave as a function of location with PDE's.

  \[
      \frac{\partial g(x)}{\partial x} = f(x)
    .\]

  We are more interested in how a system behaves as a function of time, which gives us ODEs $ \frac{dx}{dt} = f(x). $ A static relationship means that the current output only depends on the current input (no dynamics, algebraic relationsship) $ y = f(u(t)). $ A dynamic relationship means that the current output depends on past inputs. Check out 3b1b video on differential equations.

  \[
      \frac{dx}{dt}(t) = f(x(t), u(t)), \quad y(t) = g(x(t))
    .\]

  \section{Modeling}

  A model is a mathematical description of a systems behavior as a function of time. Modeling is to understand the problem, apply simplifying assumptions, and apply appropriate fundamental principles. We need to be able to solve that model for the behavior of that system. This can be done by hand for simple systems. If the model is too complex, a numerical approach may be required. Our goal is to make the model simple enough to work with but realistc enough to trust.

  \newpage

  \subsection{Potato Example}

  We want to be able to heat a potato in 2 minutes with a microwave. We could use a complex model.

  \begin{enumerate}
    \item Capture unique shape
    \item Exact thermal properties
    \item FEA Analysis for temperature distribution
  \end{enumerate}

  We could also use a simple model.

  \begin{enumerate}
    \item Potatoe is a sphere with thermal properties of water
    \item We can solve this problem really quickly using Ch.7
  \end{enumerate}

  The complex model could take days or weeks, but the simple model could take a few minutes. The results could be within 10\% of each other!

  \section{Modeling Ethics}

  We will also discuss modeling ethics. A lot of engineering decisions are made from models. We will focus on understanding the model's limits, what they cannot predict, and what how "simulations are doomed to succeed".








  \chapter{Mathmatical Foundation}

  \section{Objectives}

  \begin{enumerate}
    \item Review Complex numbers
    \item Understand ODEs
    \item Laplace Transforms
  \end{enumerate}

  \section{Complex Numbers}
  $ \sqrt{-1} \equiv i, or j. $ We will use $ j. $ In systems, i is used for current, j is for the complex number. Numbers of the form

  \[
      z = x + iy
    .\]

  are complex numbers in rectangular form. x is the real part, y is the imaginary part. Put the figure of the complex plane here.

  \paragraph{NOTE:} the imaginary part is $ y. $ not $ jy. $

  Some properties of complex numbers are the magnitude and argument.
  \[
      |z| = \sqrt{x ^2 + y ^2}, \quad \theta = \arctan{ \left( \frac{y}{x} \right)}
    .\]

  The complex conjugate is the reflection of a complex number through the real axis.

  \[
      \bar{z} = x = jy
    .\]

  Properties:

  \[
      z + \bar{z} = 2 Re(z)
    .\]

  \subsection{Euler's Formula}

  \[
      e^{j\theta} = \cos{\theta} + j\sin{\theta}
    .\]
  This leads to,

  \begin{align}
    e^{-j\theta} &= \cos{\theta} - j\sin{\theta} \\
    \cos{\theta} &= \frac{e^{j\theta} - e^{j\theta}}{2}
  \end{align}

  \subsection{Polar Form}

  Define magnitude
  \[
      r = |z| = \sqrt{x ^2 + y ^2}
    .\]

  \[
      \theta = \arctan{\frac{y}{x}}
    .\]

    \[
        x = r\cos{\theta}, y = r\sin{\theta}
      .\]

  \subsection{Complex Algebra}

  Addition and subtraction are easily done in rectangular form.

  \[
      z_{1} \pm z_{2} = \left( x_1 + jy_1 \right) \pm \left( x_2 + jy_2 \right)
    .\]

  \noindent
  Multiplication and division are easily done in polar form.


  \subsection{Examples}

  Rectangular to Polar. Remember to think about quadrants!

  \begin{align}
    z &= 1 - j \\
    |z| &= \sqrt{1 ^2 + (-1 ^2)} \\
    \theta &= \arctan{\frac{-1}{1}} = 45^{\circ}
    z &= \sqrt{2} e^{-j \frac{\pi}{4}}
  \end{align}

  Division, can be done in rectangular form by multiplying by the complex conjugate. Can also be done in polar form.

  \begin{align}
    \frac{3 + 2j}{1 - 3j} &= \frac{3 + 2j}{1 - 3j} * \frac{3 + 2j}{1 + 3j} \\
    \frac{3 - 6 + 2j + 9j}{1 + 9} &= \frac{-3 + 11j}{10}
  \end{align}

  Powers, $ z = 1 - j, z ^2 = ?. $
  \begin{align}
    z &= \sqrt{2}e^{-j \frac{\pi}{4}} \\
  \end{align}

  In fact,

  \[
      z^n = re^{j\theta}n = r^n e^{jn\theta}
    .\]

  \subsection{Complex Functions}

  \[
      z_1 \rightarrow G(z_1) \rightarrow z_2
    .\]

  Example,

  \[
      G(z_1) = \frac{z_1 + 2}{z_1^2 + z_1 + 1}
    .\]

  let $z_1 = j2$. We can evaulate the function by plugging in $ j2. $ for $ z_1. $

  \section{ODEs - Basics}

  Independent variable is time, $ t. $ The dependent variable is usually denoted as $ x. $

  Derivatives,

  \[
      \dot{x} = \frac{dx}{dt}, \quad \ddot{x} = \frac{d^2 x}{dt^2},  \quad \ldots \quad x^{(n)} = \frac{d^n x}{dt^n}
    .\]

    Standard form is to have all functions of the dependent variable on the LHS, all isolated constants and functions of time on the RHS. The RHS is considered the input or the forcing function. If the RHS = 0 the equation is homogeneous. If not, it is nonhomogeneous.

    The goal is to solve for $ x(t). $ This gives us the solution or the response.

    \subsection{Examples of Standard Form}

    \begin{align}
      \ddot x + 3 \dot x + 5x &= 0 \\
      \ddot x + 3\dot x x +5 x ^2 &= 5 \sin{2t} \\
      \dot x &= 6 + 5 \sin t
    \end{align}

    \subsection{Initial COnditions}


    When solving an ODE, there is a family of solutions. Example:

    \[
        2 \dot x + 6x = 3 \quad x(t) = Ce^{-3t} + 0.5
      .\]
    you could choose many values for C and still have a solution to the equation. No matter the value of C, $ x(t). $ still approaches 0.5. Include the graph here. Without loss of generality, we assume that the system starts at $ t = 0. $ Determining C requires knowledge of x at some time t. Commonly, the initial condition is given as $ x(t_0) = x_0. $

    \subsection{Classification of ODEs}

    Linearity generally means that $ f(x + y) = f(x) + f(y). $ Linear ODEs contain only linear functions of the dependent variable and its derivatives. Nonlinear functions of the independent variable do not make an ODE nonlinear.

    The order is the highest derivative of the dependent variable (double dot, 2nd order). A coupled set of ODEs can be reducded to a single ODE whose order is the sum of the oder of the individual ODEs.

    Example:

    \begin{align}
      3 \dot{x_1} + 5 \dot{x_2} - 7 x_2 &= 5 \\
      \dot x_2 + 4 x_1 + 6 x_2 &= 0
    \end{align}

    Add the sum of the orders of the two dependent variables. 1 order from x1 and 1 order from x2. This is a second order system, which could be represented by a single 2nd order ODE.

    \subsection{Combining Coupled ODEs}
    We have two equations.
    \begin{align}
      \dot x_1 + 4x_2 &= 3 \\
      2 \dot x_2 + x_1 &= 5
    \end{align}

    Solution,

    \[
        \dot x_1 + 4x_2 = 3 \Rightarrow \ddot x_1 + 4 x_2 = 0
      .\]

    Rearrange the second equation for x2 and substitute.

    \section{Solution}

    \subsection{Direct Integration}

    With some first order ODEs, we can rearrange as

    \[
        \frac{dx}{dt} = f(t)
      .\]
    and integrate both sides.

    \[
        \int{dx} = \int{f(t) dt}
      .\]

    \[
        x(t) = x(t_0) + \int{f(t)dt}
      .\]

    Example $ \dot x = 5. $

    \subsection{Seperation of Variables}
    Doesn't show up that often in this class.
    \[
        \frac{dx}{dt} = g(t) f(t)
      .\]

    \subsection{Trial-Solution Method}

    For any nth order linear ODE, there is a response $ x(t) = x_h + x_p. $ The response is the sum of the homogeneous solution and the particular solution. The sum of the internal behavior and the external behavior.

    Assume the solution is of the form $ x(t) = e^{\lambda t}. $ Take the derivative of $ x(t). $ n times and substitute into the ODE. Note that $ e^{\lambda t} \neq 0. $ This gives us the characteristic equation.

    \[
        (\lambda - \lambda_1)( \ldots ) = 0
      .\]




  \part{Week 2}

  \chapter{ODEs and Laplace Transforms}

  \section{Trial Solution}

  \subsection{Characteristic Equation}
  Plug in the form of the solution
  \[
      x(t) = e^{\lambda t}
    .\]
  \subsection{Example}
  \begin{align}
    \ddot x + 10 \dot x + 9x &= 5 \sin 2t \\
    \ddot x + 10 \dot x + 9x &= 0 \\
    \lambda ^2 + 10 \lambda + 9 &= 0 \\
    (\lambda + 9)(\lambda + 1) &= 0
  \end{align}

  The roots are distinct. -9, -1. The roots can be repeated, or complex as well!

  \subsection{Types of Roots}
  If all roots are distinct, there will be n different coefficients.

  \[
      \dot x + ax = 0, \quad x(t_0 = 0) = 0
    .\]
  \[
      (\lambda + a) e^{\lambda t} = 0, \quad \lambda = -a
    .\]

  \[
      x_0 = C e^{-a*0} = C, \quad x(t) = x_0 e^{-at}
    .\]
  If we have repeated roots, the coefficients gain increasing powers of time.

  \[
      x(t) = C_1 e^{\lambda t} + C_2 t e^{\lambda t} \ldots
    .\]

  Complex roots can be handled using Euler's formula.

  \[
      \lambda_{i, i+1} = \sigma \pm j\omega
    .\]

  \[
      x(t) = \ldots + C_i e^{\sigma + j\omega} + C_{i + 1} e^{\sigma - j\omega} + \ldots
    .\]
  Using eulers formula,

  \[
      x(t) = \ldots + \left( C'_i \cos \omega t + C'_{i+1} \sin \omega t \right) e^{\sigma t} + \ldots
    .\]
  The prime means that the coefficient is different from the line above. This solution is going to be oscillating.

  \section{Forced Response}

  Just discussed how to obtain $ x_h. $ Use Method of Undetermined Coefficients to get $ x_p. $ Choose a solution form based on the term in $ f(t). $

  \begin{table}
    \caption{Solution Forms}
    \centering
    \begin{tabular}{c  c}
      Term in $ f(t). $ & Form of solution $ x_p(t). $ \\
      $ A_n^t + \ldots + A_1 t + A_0. $  & $ C_n^t + \ldots + C_1 t + C_0. $\\
      $ Ae^{at}. $ & $ Ce^{at}. $ \\
      $ A\sin \omega t$ & $ C\sin \omega t . $ \\
      $ Ae^{at}\sin \omega t. $ & $ Ce^{at}\sin \omega t. $
    \end{tabular}
    \label{tab:forcedresponse}

  \end{table}
  Note, the form of the forcing function always shows up i nthe form of the solution (property of linear ODEs) See Table \ref{tab:forcedresponse}

  Substitute assumed forms of $ x_p. $ int othe ODe and determine the coefficients, then go back and solve the homogeneous problem seperately. Add the two solutions with linear superpositions. Finally, find the coefficients to the homogeneous solution.


  \newpage

  \section{Laplace Transforms}
  Finding solutions in the time domain is hard. While using laplace transforms takes longer, the solution is generally easier to find (algebra over calculus). The laplace transform is a linear operator, so it is useful for

  \begin{enumerate}
    \item Nonhomogeneous equations with a forcing function of time
    \item Sets/systems of equations
  \end{enumerate}

  Linear ODEs become algebraic relationships, and convolution becomes multiplication.

  \begin{equation}
    F(s) = \mathcal{L}\{f(t)\} = \int_{0-}^{\infty} e^{st} f(t)dt
  \end{equation}

  Assume $ f(t) = 0, t < 0. $ We tend to start caring about what happens at time $ t = 0. $ However, interesting "stuff" happens at time $ t = 0. $

  \begin{enumerate}
    \item "stuff" - step changes, impulses
    \item We need a way to denote before and after this stuff happens
  \end{enumerate}

  Let $ \epsilon, $ be an infitessimally small unit of time. $ 0-, 0+ $ occur $ \epsilon $ seconds before and after time $ t = 0. $ Unless stated explicitly, we assume $ f(t) = 0 \forall t < 0. $

  \subsection{Inverse Laplace Transform}

  The definition of inverse laplace tranforms is complex, so we use lookup tables in the book.

  Some common examples,

  \[
      f(t) = e^{-at} \iff F(s) = \frac{1}{s + a}, \quad a > 0
    .\]

  \subsection{Properties}

  Laplace Transforms are linear. Inverse Laplace transforms too.

  \[
      \mathcal{L}\{af(t) + bg(t)\} = a \mathcal{L}\{f(t)\} + b \mathcal{L}\{g(t)\}
    .\]

  This property does NOT hold for multiplication. Instead, multiplication corresponds to a convolution integral in the time domain.

  \[
      F(s)G(s) = \mathcal{L}\left\{\int_0^t f(t)g(t - \tau) d\tau\right\}
    .\]

  Derivatives,

  \begin{equation}
    \mathcal{L}\{\dot{f(t)}\} = sF(s) - f(0)
  \end{equation}

  \begin{equation}
    \mathcal{L}\{\ddot{f(t)}\} = s ^2 F(s) - sf(0) - \dot{f(0)}
  \end{equation}

  Integrals,

  \[
      \mathcal{L}\left\{\int f(\tau)d \tau \right\} = \frac{1}{s} F(s)
    .\]


  \chapter{Laplace Transforms}

  \section{Laplace Transforms of Special Functions}

  \begin{enumerate}
    \item Unit Step $ \mathcal{L}\{u_s\} = \frac{1}{s}. $
    \item Unit Ramp $ \mathcal{L}\{u_r\} = \frac{1}{s ^2}. $
    \item Unit Pulse $ \mathcal{L}\{u_p\} = \frac{1}{sD} \left( 1-e^{sD} \right). $
    \item As D approaches zero, we get the unit impulse function
    \item $ \mathcal{L}\{\delta(t)\} = 1. $
  \end{enumerate}

  \section{Properties of Laplace Transforms}

  \subsection{Time Shift}
  Many time shifts occur due to distance traveled. E.g. Flow through a pipe. A time shift results in a multiplication by an exponential in the frequency domain.
  \[
      \mathcal{L}\{f(t-\alpha)\} = e^{-\alpha s}F(s)
    .\]

  \subsection{Multiplication by Exponential}
  Multiplication by an exp in the time domain results in a shift in the frequency domain.
  \[
      \mathcal{L}\{e^{-\alpha t}f(t)\} = F(s + \alpha)
    .\]

  \section{Initial Value Theorem}

  Sometimes we would like to find the value of $ x(t) $ at $ t = 0^+. $ Given the laplace transform of the function we have the initial value theorem (IVT)

  \begin{equation}
    x(0^+) = \lim_{t \rightarrow 0} x(t) = \lim_{s \rightarrow \infty} sX(s)
  \end{equation}

  This is only applicable if the limit exists, and the transforms and derivatives of $ x(t) $ exist.

  \section{Final Value Theorem}

  Sometimes we would like to know the limit of a function as time goes to infinity. If the limit exists, and transforms/derivatives of $ x(t) $ exist we have the final value theorem (FVT).

  \begin{equation}
    \lim_{t \rightarrow \infty} x(t) = \lim_{s \rightarrow 0} sX(s)
  \end{equation}

  \section{Example - Solving ODE with Laplace}

  We have the EOM,

  \[
      m\ddot x + c \dot x + kx = 0
    .\]
  \noindent
  laplace transform and initial conditions gives us

  \[
      m(s ^2X(s) -s) + c(sX(s) - 1) + kX(s) = 0
    .\]
  \noindent
  rearrange,
  \[
      (ms ^2 + cs + k)X(s) = ms + c
    .\]

  \[
      X(s) = \frac{ms + c}{ms ^2 + cs + k}
    .\]

  \subsection{Partial Fraction Expansion}
  we can find $ x(t) $ with inverse laplace transforms. Our transfer function is a ration of polynomials.

  \[
      X(s) = \frac{N(s)}{D(s)}
    .\]

  \noindent

  Our goal is to express $ X(s)$ as a suitable sum of fractions by dividing $ D(s) $ into 1st and 2nd order roots. Then we can preform the inverse laplace transform.

  \subsubsection{Case 1: Distinct Roots}

  If $ D(s) $ contains $ (s + p_i). $ The corresponding factor is,

  \[
      \frac{A_i}{s + p_i}
    .\]

  where $ A_i $ is the called the "residue".

  \subsubsection{Case 2: Repeated Roots}

  If $ D(s) $ contains $ (s + p_i)^{r_i}. $ The corresponding factor is,

  \[
      \frac{A_{r_i}}{ \left( s + p_i \right)^{r_i} } + \frac{A_{r_i-1}}{ \left( s + p_i \right)^{r_{i}-1} } + \ldots
    \]

  from the table,

  \begin{equation}
    \mathcal{L}^{-1}\left\{\frac{1}{(s+a)^n}\right\} = \frac{1}{(n-1)!}t^{n-1}e^{-at}
  \end{equation}

  increase the power of t as you have more repetition!

  \subsubsection{Case 3: Complex Roots}

  If $ D(s) $ contains $ s ^2 + as + b. $ The corresponding factor is,

  \[
      \frac{Bs + C}{s ^2 + as + b}
    .\]

  Before taking the inverse Laplace transform, we need to complete the square

  \[
      s ^2 + as + b = (s + \sigma) ^2 + \omega ^2
    .\]

  eg,

  \[
      s ^2 + 2s + 2 = (s ^2 + 2s + 1) + 1 = (s + 1) ^2 + 1
    .\]

  The goal is to write in terms of sine and cosine. This introduces oscillation in our signal.

  \[
      = A_1 \mathcal{L}^{-1}\left\{\frac{s + \sigma}{(s + \sigma) ^2 + \omega ^2}\right\} + A_2 \mathcal{L}^{-1}\left\{\frac{\omega}{(s + \sigma) ^2 + \omega ^2}\right\}
    .\]

  \section{Parts of the Response}

  The \textbf{Transient Reponse} is the part that disappears with time. The parts that remain with time are the \textbf{Steady-state Response}. The \textbf{Free Response} is the part that depends on the ICs, and the \textbf{Forced Response} is the part due to the forcing function. We can write the total response as a sum of the transient and steady state or the sum of the free and forced response! Note that we will not always have two terms.

  \section{Transfer Functions}

  \textbf{Transfer Functions} capture the dynamics of the system \textbf{independent of ICs and input} (forcing functions)

  \begin{equation}
    T(s) = \frac{X(s)}{F(s)}
  \end{equation}

  example,

  \[
      \dot x + ax = f(t) \Rightarrow (s+a)X(s) = F(s)
    .\]

  \[
      T(s) = \frac{X(s)}{F(s)} = \frac{1}{s+a}
    .\]

  Denominator of transfer function is the caracteristic equation, it can tell us about the general behavior of the system.

  \[
      T(S) = \frac{1}{s ^2 + 7s + 10}, \quad r = -2, -5
    .\]

  \begin{itemize}
    \item Roots are real - no oscillation in response
    \item Roots are negative - model is stable and free response converges to zero
  \end{itemize}



  Transfer function is internal to the system, and is a mapping between the input and the output. We can also go back and forth between ODE and Transfer Function.

  \[
      G: X \rightarrow F
    .\]

  The transfer function is a ratio of polynomials. The system zeroes are the roots of the numerator and the poles are the roots of the denominator.

  Example,

  \[
      G(s) = \frac{s + 1}{s + 2}
    .\]

  has a zero at -1 and a pole at -2. Zeroes are given by models with derivatives of the input. The numerator dynamics can significantly alter the response but the analysis is the same.

  Note,

  \[
      g(t) = u_s(t) \Rightarrow \dot g(t) = \delta (t)
    .\]

  \section{Transfer Function and Convolution}

  For LTI systems, teh system response is the convolution of the input function and the system's impulse response. From the definition of a transfer function, the response of our system is,

  \begin{equation}
    X(s) = G(s)F(s)
  \end{equation}

  We can also think about $ G(s) $ as the impulse response of our system.

  \[
      f(t) = \delta (t) \Rightarrow F(s) = 1 \Rightarrow X(s) = G(s)F(s) = G(s) \cdot 1
    .\]



  \section{section name}

\end{document}
